{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86d9ebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb600ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bfb041a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2523cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b55586b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3ee72df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinma\\AppData\\Local\\Temp\\ipykernel_21540\\2558029091.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_encoded = df.replace({'sentiment' : {'positive': 1 , 'negative': 0}})\n"
     ]
    }
   ],
   "source": [
    "df_encoded = df.replace({'sentiment' : {'positive': 1 , 'negative': 0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3eaac1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad0a576f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "1    25000\n",
       "0    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609367d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the following data we will use LSTM model (Long short-term memory) for sentiment analysis we will avoid using RNN as the data is textual \n",
    "#RNN mai memory nahi hai LSTM mai hai aur data mai vector zyada hai toh better rahega ki hamm LSTM use karree low data pai RnN chal  Jata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "679c088b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.20.0rc0-cp313-cp313-win_amd64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\vinma\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (2.2.2)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\vinma\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\vinma\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\vinma\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vinma\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\vinma\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\vinma\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (4.13.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-1.17.2-cp313-cp313-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\vinma\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (1.72.0rc1)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Using cached keras-3.11.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\vinma\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\vinma\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\vinma\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vinma\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vinma\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vinma\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vinma\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached markdown-3.8.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\vinma\\appdata\\roaming\\python\\python313\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.2.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\vinma\\appdata\\roaming\\python\\python313\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\vinma\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\vinma\\appdata\\roaming\\python\\python313\\site-packages (from keras>=3.10.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\vinma\\appdata\\roaming\\python\\python313\\site-packages (from keras>=3.10.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\vinma\\appdata\\roaming\\python\\python313\\site-packages (from keras>=3.10.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\vinma\\appdata\\roaming\\python\\python313\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\vinma\\appdata\\roaming\\python\\python313\\site-packages (from rich->keras>=3.10.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\vinma\\appdata\\roaming\\python\\python313\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\vinma\\appdata\\roaming\\python\\python313\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Using cached tensorflow-2.20.0rc0-cp313-cp313-win_amd64.whl (332.0 MB)\n",
      "Using cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached keras-3.11.1-py3-none-any.whl (1.4 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Using cached markdown-3.8.2-py3-none-any.whl (106 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached wrapt-1.17.2-cp313-cp313-win_amd64.whl (38 kB)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, termcolor, tensorboard-data-server, opt_einsum, markdown, google_pasta, gast, astunparse, tensorboard, keras, tensorflow\n",
      "\n",
      "   ----------------------------------------  0/13 [libclang]\n",
      "   ----------------------------------------  0/13 [libclang]\n",
      "   ------ ---------------------------------  2/13 [wrapt]\n",
      "   --------------- ------------------------  5/13 [opt_einsum]\n",
      "   ------------------ ---------------------  6/13 [markdown]\n",
      "   ------------------------ ---------------  8/13 [gast]\n",
      "   ------------------------------ --------- 10/13 [tensorboard]\n",
      "   ------------------------------ --------- 10/13 [tensorboard]\n",
      "   ------------------------------ --------- 10/13 [tensorboard]\n",
      "   ------------------------------ --------- 10/13 [tensorboard]\n",
      "   ------------------------------ --------- 10/13 [tensorboard]\n",
      "  Attempting uninstall: keras\n",
      "   ------------------------------ --------- 10/13 [tensorboard]\n",
      "    Found existing installation: keras 3.9.2\n",
      "   ------------------------------ --------- 10/13 [tensorboard]\n",
      "   --------------------------------- ------ 11/13 [keras]\n",
      "   --------------------------------- ------ 11/13 [keras]\n",
      "    Uninstalling keras-3.9.2:\n",
      "   --------------------------------- ------ 11/13 [keras]\n",
      "      Successfully uninstalled keras-3.9.2\n",
      "   --------------------------------- ------ 11/13 [keras]\n",
      "   --------------------------------- ------ 11/13 [keras]\n",
      "   --------------------------------- ------ 11/13 [keras]\n",
      "   --------------------------------- ------ 11/13 [keras]\n",
      "   --------------------------------- ------ 11/13 [keras]\n",
      "   --------------------------------- ------ 11/13 [keras]\n",
      "   --------------------------------- ------ 11/13 [keras]\n",
      "   --------------------------------- ------ 11/13 [keras]\n",
      "   --------------------------------- ------ 11/13 [keras]\n",
      "   --------------------------------- ------ 11/13 [keras]\n",
      "   --------------------------------- ------ 11/13 [keras]\n",
      "   --------------------------------- ------ 11/13 [keras]\n",
      "   --------------------------------- ------ 11/13 [keras]\n",
      "   --------------------------------- ------ 11/13 [keras]\n",
      "   --------------------------------- ------ 11/13 [keras]\n",
      "   --------------------------------- ------ 11/13 [keras]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ------------------------------------ --- 12/13 [tensorflow]\n",
      "   ---------------------------------------- 13/13 [tensorflow]\n",
      "\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google_pasta-0.2.0 keras-3.11.1 libclang-18.1.1 markdown-3.8.2 opt_einsum-3.4.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0rc0 termcolor-3.1.0 wrapt-1.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "975632d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM,Embedding \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae77681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here using pad_sequences for the first time it makes the token length by padding the shorter ones so that unifor tokens are provided to the nural network \n",
    "# aise provide karna is mandatory so tokenisation ke badd we will use padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0867f696",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data , test_data = train_test_split(df_encoded, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a6d247b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29fa5276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a598c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words =5000)\n",
    "tokenizer.fit_on_texts(train_data['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fba0bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(tokenizer.texts_to_sequences(train_data['review']), maxlen=200)\n",
    "x_test = pad_sequences(tokenizer.texts_to_sequences(test_data['review']), maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f77f32d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1935,    1, 1200, ...,  205,  351, 3856],\n",
       "       [   3, 1651,  595, ...,   89,  103,    9],\n",
       "       [   0,    0,    0, ...,    2,  710,   62],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 1641,    2,  603],\n",
       "       [   0,    0,    0, ...,  245,  103,  125],\n",
       "       [   0,    0,    0, ...,   70,   73, 2062]],\n",
       "      shape=(40000, 200), dtype=int32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e205851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  995,  719,  155],\n",
       "       [  12,  162,   59, ...,  380,    7,    7],\n",
       "       [   0,    0,    0, ...,   50, 1088,   96],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,  125,  200, 3241],\n",
       "       [   0,    0,    0, ..., 1066,    1, 2305],\n",
       "       [   0,    0,    0, ...,    1,  332,   27]],\n",
       "      shape=(10000, 200), dtype=int32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b30926cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data['sentiment']\n",
    "y_test = test_data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a1447141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39087    0\n",
       "30893    0\n",
       "45278    1\n",
       "16398    0\n",
       "13653    0\n",
       "        ..\n",
       "11284    1\n",
       "44732    1\n",
       "38158    0\n",
       "860      1\n",
       "15795    1\n",
       "Name: sentiment, Length: 40000, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9eadc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(200,)))\n",
    "model.add(Embedding(input_dim = 5000, output_dim = 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c49e557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dim = 5000 chee vocabulary size most frequent words ach consider karsee \n",
    "# output_dim = 128 chee embedding vector size je ki 128 dimensional vector banavsee\n",
    "# input_length = 500 chee maximum length of the input sequence je ki 500 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "488ee47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here droput drops 20% randomly from the input layer to avoid overfitting and recurrent_dropout drops 20% randomly from the output layer to avoid overfitting\n",
    "# recurrent_droput mai bhi drop hi hOga just inside thw LSTM cell jo ki hidden connections hote hai\n",
    "# 128 ji che ee lstm unit che je ki store karrse information anee decide karse waht to keep and wjat not , output apsee relevant to the next steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "033fb261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apdee binary classification karre chee thus used 1 \n",
    "#sigmoid activation pann use karre chee as binary classfification \n",
    "#model = Sequential()\n",
    "# If output > 0.5 = class 1\n",
    "# If output ≤ 0.5 = class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b539e711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_7 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m640,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">771,713</span> (2.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m771,713\u001b[0m (2.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">771,713</span> (2.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m771,713\u001b[0m (2.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "01376222",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ded52db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ayaa model.compile tells the model how to update weights , how to calculate error and what metrics to track \n",
    "#optimizer adam is algorithm to update weights works well for most of the cases also adjusts learning dynamically\n",
    "#loss binary_crossentropy is used for binary classification problems measures the difference between predicted and actual values\n",
    "#metrics accuracy is used to track the performance of the model during training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ab02f589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 251ms/step - accuracy: 0.7856 - loss: 0.4613 - val_accuracy: 0.8581 - val_loss: 0.3388\n",
      "Epoch 2/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 225ms/step - accuracy: 0.8558 - loss: 0.3466 - val_accuracy: 0.8455 - val_loss: 0.3588\n",
      "Epoch 3/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 217ms/step - accuracy: 0.8749 - loss: 0.3028 - val_accuracy: 0.8608 - val_loss: 0.3319\n",
      "Epoch 4/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 197ms/step - accuracy: 0.8918 - loss: 0.2718 - val_accuracy: 0.8754 - val_loss: 0.3044\n",
      "Epoch 5/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 196ms/step - accuracy: 0.8897 - loss: 0.2684 - val_accuracy: 0.8529 - val_loss: 0.3574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d68c002a50>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 5, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab883ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - accuracy: 0.8526 - loss: 0.3524\n"
     ]
    }
   ],
   "source": [
    "loss , accuracy = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f5a38b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3523964285850525\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e0944008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8525999784469604\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a1faf972",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('movie_review_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b91f2a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tokenizer.pkl']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(tokenizer, 'tokenizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c09470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictive_system(review):\n",
    "    sequences = tokenizer.texts_to_sequences([review])\n",
    "    \n",
    "    padded_sequence = pad_sequences(sequences, maxlen=200)\n",
    "    \n",
    "    prediction = model.predict(padded_sequence)[0][0]\n",
    "    \n",
    "    if prediction >= 0.5:\n",
    "        result = \"Positive Review\"\n",
    "    else:\n",
    "        result = \"Negative Review\"\n",
    "    \n",
    "    return f\"Prediction Score: {prediction:.4f} → {result}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "25926b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step\n",
      "Prediction Score: 0.9099 → Positive 😃\n"
     ]
    }
   ],
   "source": [
    "print(predictive_system(\"I loved the movie, it was fantastic!\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d2b596",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
